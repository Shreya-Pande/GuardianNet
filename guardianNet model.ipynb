{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_Pgwmgns9H3Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load NSL-KDD\n",
        "nsl_train = pd.read_csv(\"/content/KDDTrain+.txt\", header=None)\n",
        "nsl_test = pd.read_csv(\"/content/KDDTest+.txt\", header=None)\n",
        "\n",
        "nsl_columns = [\n",
        "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
        "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in',\n",
        "    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
        "    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
        "    'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate',\n",
        "    'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
        "    'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
        "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
        "    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
        "    'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
        "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n",
        "    'attack_category', 'label'\n",
        "]\n",
        "nsl_train.columns = nsl_columns\n",
        "nsl_test.columns = nsl_columns\n",
        "\n",
        "# Load UNSW-NB15\n",
        "unsw_train = pd.read_csv(\"/content/UNSW_NB15_training-set.csv\")\n",
        "unsw_test = pd.read_csv(\"/content/UNSW_NB15_testing-set.csv\")\n",
        "\n",
        "unsw_columns = ['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes',\n",
        "       'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',\n",
        "       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',\n",
        "       'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n",
        "       'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm',\n",
        "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
        "       'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm',\n",
        "       'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label']\n",
        "unsw_test = unsw_test[unsw_columns]\n",
        "\n",
        "# Rename and cleanup\n",
        "unsw_train.rename(columns={'dur': 'duration', 'proto': 'protocol_type', 'attack_cat': 'attack_category'}, inplace=True)\n",
        "unsw_test.rename(columns={'dur': 'duration', 'proto': 'protocol_type', 'attack_cat': 'attack_category'}, inplace=True)\n",
        "unsw_train.drop(columns=['id'], inplace=True)\n",
        "unsw_test.drop(columns=['id'], inplace=True)\n",
        "\n",
        "# Merge all data\n",
        "nsl_data = pd.concat([nsl_train, nsl_test], axis=0).reset_index(drop=True)\n",
        "unsw_data = pd.concat([unsw_train, unsw_test], axis=0).reset_index(drop=True)\n",
        "\n",
        "df = pd.concat([nsl_data, unsw_data], axis=0, join=\"outer\").reset_index(drop=True)\n",
        "\n",
        "# Backup attack_category if exists\n",
        "if 'attack_category' in df.columns:\n",
        "    labels = df['attack_category']\n",
        "else:\n",
        "    labels = None\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill NaNs in categorical columns\n",
        "for col in ['protocol_type', 'service', 'flag', 'state', 'attack_category']:\n",
        "    if col in df.columns:\n",
        "        df[col].fillna('unknown', inplace=True)\n",
        "\n",
        "# Fill numerical NaNs\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[num_cols] = df[num_cols].fillna(0)\n",
        "\n",
        "# Drop columns with >50% missing values\n",
        "df = df.loc[:, df.isnull().mean() < 0.5]\n",
        "\n",
        "# Remove non-numeric columns temporarily for encoding\n",
        "non_numeric_cols = df.select_dtypes(exclude=['number']).columns.tolist()\n",
        "print(f\"Non-numeric columns: {non_numeric_cols}\")\n"
      ],
      "metadata": {
        "id": "ZZnoDCC_9-1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Safely fill NaNs in categorical columns\n",
        "for col in ['protocol_type', 'service', 'flag', 'attack_category', 'state']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].fillna('unknown')  # ✅ No inplace=True\n",
        "\n",
        "# Fill numerical NaNs\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df[num_cols] = df[num_cols].fillna(0)\n",
        "\n",
        "# Drop columns with >50% missing values\n",
        "df = df.loc[:, df.isnull().mean() < 0.5]\n",
        "\n",
        "# Get non-numeric columns for encoding\n",
        "non_numeric_cols = df.select_dtypes(exclude=['number']).columns.tolist()\n",
        "print(f\"🧾 Non-numeric columns: {non_numeric_cols}\")\n"
      ],
      "metadata": {
        "id": "VTLslNL9-9G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# ➤ Step 1: Handle missing values\n",
        "for col in ['protocol_type', 'service', 'flag', 'attack_category', 'state']:\n",
        "    if col in df.columns:\n",
        "        df.loc[:, col] = df[col].fillna('unknown')\n",
        "\n",
        "# Fill numerical NaNs\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "df.loc[:, num_cols] = df[num_cols].fillna(0)\n",
        "\n",
        "# Drop columns with >50% missing values\n",
        "df = df.loc[:, df.isnull().mean() < 0.5]\n",
        "\n",
        "# ➤ Step 2: Preserve attack_category\n",
        "if 'attack_category' in df.columns:\n",
        "    attack_category = df['attack_category'].copy()\n",
        "    print(\"✅ attack_category preserved separately\")\n",
        "\n",
        "# ➤ Step 3: Copy features for transformation\n",
        "X = df.drop(columns=['attack_category']) if 'attack_category' in df.columns else df.copy()\n",
        "\n",
        "# ➤ Step 4: One-hot encode 'protocol_type', 'flag', 'state'\n",
        "categorical_cols = [col for col in ['protocol_type', 'flag', 'state'] if col in X.columns]\n",
        "if categorical_cols:\n",
        "    X = pd.get_dummies(X, columns=categorical_cols, dtype=int)\n",
        "    print(f\"✅ One-hot encoded: {categorical_cols}\")\n",
        "\n",
        "# ➤ Step 5: Frequency encode 'service'\n",
        "if 'service' in X.columns:\n",
        "    service_counts = X['service'].value_counts().to_dict()\n",
        "    X['service'] = X['service'].map(service_counts)\n",
        "    print(\"✅ Frequency encoded: service\")\n",
        "\n",
        "# ➤ Step 6: Double-check for non-numeric leftovers\n",
        "non_numeric_cols = X.select_dtypes(exclude=['number']).columns.tolist()\n",
        "if non_numeric_cols:\n",
        "    print(f\"⚠️ Dropping unexpected non-numeric cols: {non_numeric_cols}\")\n",
        "    X.drop(columns=non_numeric_cols, inplace=True)\n",
        "\n",
        "# ➤ Step 7: Min-Max Scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"✅ Final Scaling Done!\")\n",
        "print(f\"🔢 Final shape for Autoencoder: {X_scaled.shape}\")\n"
      ],
      "metadata": {
        "id": "bA1CCHc--_xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "input_dim = X_scaled.shape[1]\n",
        "encoding_dim = 64  # You can tune this\n",
        "\n",
        "# Input layer\n",
        "input_layer = layers.Input(shape=(input_dim,))\n",
        "\n",
        "# Encoder\n",
        "encoded = layers.Dense(256, activation='relu')(input_layer)\n",
        "encoded = layers.Dense(128, activation='relu')(encoded)\n",
        "bottleneck = layers.Dense(encoding_dim, activation='relu', name='bottleneck')(encoded)\n",
        "\n",
        "# Decoder\n",
        "decoded = layers.Dense(128, activation='relu')(bottleneck)\n",
        "decoded = layers.Dense(256, activation='relu')(decoded)\n",
        "output_layer = layers.Dense(input_dim, activation='sigmoid')(decoded)\n",
        "\n",
        "# Autoencoder model\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
        "autoencoder.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='mse')\n",
        "\n",
        "# Encoder model for feature extraction\n",
        "encoder = Model(inputs=input_layer, outputs=bottleneck)\n",
        "\n",
        "# Train autoencoder\n",
        "history = autoencoder.fit(\n",
        "    X_scaled, X_scaled,\n",
        "    epochs=50,\n",
        "    batch_size=1024,\n",
        "    shuffle=True,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],\n",
        "    verbose=1\n",
        ")\n",
        "X_compressed = encoder.predict(X_scaled)"
      ],
      "metadata": {
        "id": "TY29lu_2_Cx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_compressed, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "K4zjqBMk_XtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "xgb = XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.05)\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "preds = xgb.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))"
      ],
      "metadata": {
        "id": "n7lRrHv3_TfF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}